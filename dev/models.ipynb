{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commercial Bank Customer Retention Prediction\n",
    "\n",
    "## APSTA-GE.2401: Statistical Consulting\n",
    "\n",
    "## Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on: 12/07/2020\n",
    "\n",
    "Modified on: 12/08/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This script contains the machine learning models.\n",
    "\n",
    "### Research Design\n",
    "\n",
    "The strategy of supervised learning is to train models using the `X_train` data and validate model performance using the `y_train` data. After training, we fit the model to the `X_test` data. The model will then generate predictions, `y_test`, based on `X_test`. \n",
    "\n",
    "To increase model performance, we splited the train set into two sets: 80% of the train data goes to the `X_train` set and 20% of the data goes to the `X_test` set. Then, we conducted a 5-fold cross validation and selected the best performed model output. We also find tuned hyperparameters using randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS! All modules are imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print('SUCCESS! All modules are imported.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/X_train.csv')\n",
    "y = pd.read_csv('../data/y_train.csv')\n",
    "X_hold = pd.read_csv('../data/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model-ready training set has 145296 rows and 76 columns.\n",
      "The model-ready validation set has 145296 rows and 2 columns.\n",
      "The model-ready testing set has 76722 rows and 76 columns.\n"
     ]
    }
   ],
   "source": [
    "print('The model-ready training set has {} rows and {} columns.'.format(X.shape[0], X.shape[1]))\n",
    "print('The model-ready validation set has {} rows and {} columns.'.format(y.shape[0], y.shape[1]))\n",
    "print('The model-ready testing set has {} rows and {} columns.'.format(X_true.shape[0], X_hold.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_train = X['cust_no']\n",
    "ID_test = y['cust_no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop('cust_no', axis=1)\n",
    "y = y.drop('cust_no', axis=1)\n",
    "X_hold = X_true.drop('cust_no', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1061)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After train test split, the training set has 116236 rows and 75 columns.\n",
      "After train test split, the train has 116236 labels.\n",
      "After train test split, the test set has 29060 rows and 75 columns.\n",
      "After train test split, the test has 29060 labels.\n"
     ]
    }
   ],
   "source": [
    "print('After train test split, the training set has {} rows and {} columns.'.format(X_train.shape[0], X_train.shape[1]))\n",
    "print('After train test split, the train has {} labels.'.format(y_train.shape[0]))\n",
    "print('After train test split, the test set has {} rows and {} columns.'.format(X_test.shape[0], X_test.shape[1]))\n",
    "print('After train test split, the test has {} labels.'.format(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "scaled_X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, sig, Vt = np.linalg.svd(scaled_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "fig = plt.figure(num=None, figsize=(5, 5), dpi=150, tight_layout=True)\n",
    "plt.plot(fpr_logreg, tpr_logreg)\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cumulative Information Rate')\n",
    "plt.title('Singular Value Decomposition Results')\n",
    "plt.show()\n",
    "fig.savefig('../results/svd.png', dpi=fig.dpi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
