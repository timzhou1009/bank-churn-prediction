{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commercial Bank Customer Retention Prediction\n",
    "\n",
    "## APSTA-GE.2401: Statistical Consulting\n",
    "\n",
    "## Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on: 12/08/2020\n",
    "\n",
    "Modified on: 12/08/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This script processes data from the proprocess step.\n",
    "\n",
    "### Data\n",
    "\n",
    "The data are preprocessed feature sets:\n",
    "\n",
    "  - `X_train.csv`: contains all features in Q3 and Q4 of 2019 for training. Imported as `X`.\n",
    "  - `y_train.csv`: contains the label variable for validation. Imported as `y`.\n",
    "  - `X_test.csv`: contains all features in Q1 of 2020 for testing. Imported as `X_true`.\n",
    "   \n",
    "After importing the data, we confirmed that both train sets have the same number of records: **145296**. We also confirmed that the testing set has **76722** records.\n",
    "\n",
    "### Procedures\n",
    "\n",
    "We first inspected the feature set. \n",
    "\n",
    "1. There are 55 features in the feature set. \n",
    "\n",
    "2. We checked if there are any missing values in the set. We found multiple columns that contain missing values, ranging from 0.005% to 100%. For columns containing a large portion of missing values, we dropped the column to reduce computational burden. For columns containing a small portion of missing values, we applied a deep learning library, [Datawig](https://github.com/awslabs/datawig), which learns machine learning models using deep neural networks to impute missing values in the data.\n",
    "\n",
    "    - After dropping columns containing large portion of missing values, we reduced number of features to 45.\n",
    "\n",
    "3. We then performed dummy coding to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS! All modules are imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, date\n",
    "\n",
    "print('SUCCESS! All modules are imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/preprocess/X_train.csv')\n",
    "y = pd.read_csv('../data/preprocess/y_train.csv')\n",
    "X_true = pd.read_csv('../data/preprocess/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proprocessed training set has 145296 rows and 56 columns.\n",
      "The proprocessed validation set has 145296 rows and 2 columns.\n",
      "The proprocessed testing set has 76722 rows and 56 columns.\n"
     ]
    }
   ],
   "source": [
    "print('The proprocessed training set has {} rows and {} columns.'.format(X.shape[0], X.shape[1]))\n",
    "print('The proprocessed validation set has {} rows and {} columns.'.format(y.shape[0], y.shape[1]))\n",
    "print('The proprocessed testing set has {} rows and {} columns.'.format(X_true.shape[0], X_true.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing(dat):\n",
    "    '''Print missing values in each column of the dat\n",
    "    @Param df dat: input data frame\n",
    "    '''\n",
    "    missing_val = dat.isnull().sum()\n",
    "    for index in missing_val.index:\n",
    "        if missing_val[index] > 0:\n",
    "            print('{} has {} missing values. ({:.4%})'.format(index, missing_val[index], missing_val[index]/len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_cat_dummy(dat, col):\n",
    "    '''Print descriptive summary of the input column\n",
    "    @Param df dat: input data frame\n",
    "    @Param str col: column name as a string\n",
    "    '''\n",
    "    count = 0\n",
    "    levels = dat[col].value_counts().index\n",
    "    for level in levels:\n",
    "        dat[col] = dat[col].replace(level, count)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_df_dummy(dat, col, day0, fmt):\n",
    "    '''Convert col in dat to float using day0 as the reference date\n",
    "    @Param df dat: input data frame\n",
    "    @Param str col: column name\n",
    "    @Param datetime day0: reference date\n",
    "    @Param str fmt: date time format\n",
    "    '''\n",
    "    dat[col] = pd.to_datetime(dat[col], format=fmt, errors='ignore')\n",
    "    for index in dat[col].index:\n",
    "        dat.loc[index, col] = day0 - dat.loc[index, col]\n",
    "        dat.loc[index, col] = dat.loc[index, col].total_seconds() / (24 * 60 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X (Feature for Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "We first processed missing values in the data. Multiple columns contain missing values. The percentage of missing values in each column ranges from 0.0048% to 100.00%. We removed columns containing large portion of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B6 has 8878 missing values. (6.1103%)\n",
      "E2 has 6370 missing values. (4.3842%)\n",
      "E3 has 6370 missing values. (4.3842%)\n",
      "E4 has 84483 missing values. (58.1454%)\n",
      "E5 has 55129 missing values. (37.9425%)\n",
      "E6 has 7538 missing values. (5.1880%)\n",
      "E7 has 142402 missing values. (98.0082%)\n",
      "E8 has 127381 missing values. (87.6700%)\n",
      "E9 has 145227 missing values. (99.9525%)\n",
      "E10 has 816 missing values. (0.5616%)\n",
      "E11 has 145296 missing values. (100.0000%)\n",
      "E12 has 121324 missing values. (83.5013%)\n",
      "E13 has 127502 missing values. (87.7533%)\n",
      "E14 has 90010 missing values. (61.9494%)\n",
      "E16 has 68530 missing values. (47.1658%)\n",
      "E18 has 62147 missing values. (42.7727%)\n",
      "C1 has 7 missing values. (0.0048%)\n",
      "C2 has 7 missing values. (0.0048%)\n",
      "I1 has 64 missing values. (0.0440%)\n",
      "I5 has 11604 missing values. (7.9865%)\n",
      "I9 has 145296 missing values. (100.0000%)\n",
      "I10 has 128487 missing values. (88.4312%)\n",
      "I13 has 143108 missing values. (98.4941%)\n",
      "I14 has 129650 missing values. (89.2316%)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "check_missing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with large portion of missing values\n",
    "col_to_drop = ['E7', 'E8', 'E9', 'E11', 'E12', 'E13', 'I9', 'I10', 'I13', 'I14']\n",
    "X = X.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping columns containing large portion of missing values, now the set has 46 columns.\n"
     ]
    }
   ],
   "source": [
    "print('After dropping columns containing large portion of missing values, now the set has {} columns.'.format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B6 has 8878 missing values. (6.1103%)\n",
      "E2 has 6370 missing values. (4.3842%)\n",
      "E3 has 6370 missing values. (4.3842%)\n",
      "E4 has 84483 missing values. (58.1454%)\n",
      "E5 has 55129 missing values. (37.9425%)\n",
      "E6 has 7538 missing values. (5.1880%)\n",
      "E10 has 816 missing values. (0.5616%)\n",
      "E14 has 90010 missing values. (61.9494%)\n",
      "E16 has 68530 missing values. (47.1658%)\n",
      "E18 has 62147 missing values. (42.7727%)\n",
      "C1 has 7 missing values. (0.0048%)\n",
      "C2 has 7 missing values. (0.0048%)\n",
      "I1 has 64 missing values. (0.0440%)\n",
      "I5 has 11604 missing values. (7.9865%)\n"
     ]
    }
   ],
   "source": [
    "check_missing(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Meaningless Columns\n",
    "\n",
    "Based on the codebook, after mining into the data, we determined that the following columns contain meaningless information and, therefore, we dropped these columns:\n",
    "\n",
    "- `I8`: constellation. We don't believe constellation can alter customer behavior.\n",
    "- `I12`: field description. Contain only 1 different values.\n",
    "- `I15`: QR code recipient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_drop = ['I8', 'I12', 'I15']\n",
    "X = X.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping columns containing large portion of missing values, now the set has 43 columns.\n"
     ]
    }
   ],
   "source": [
    "print('After dropping columns containing large portion of missing values, now the set has {} columns.'.format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Coding\n",
    "\n",
    "Before applying `Datawig`, we dummy coded categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Date Time Columns\n",
    "\n",
    "To dummy code columns containing date and time, we used `2019-07-01` as day0 and converted those date time into numeric inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cust_no', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'B1', 'B2',\n",
       "       'B3', 'B4', 'B5', 'B6', 'B7', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E10',\n",
       "       'E14', 'E15', 'E16', 'E17', 'E18', 'C1', 'C2', 'I1', 'I2', 'I3', 'I4',\n",
       "       'I5', 'I6', 'I7', 'I11', 'I16', 'I17', 'I18', 'I19', 'I20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_df_dummy(dat, col, day0, fmt):\n",
    "    '''Convert col in dat to float using day0 as the reference date\n",
    "    @Param df dat: input data frame\n",
    "    @Param str col: column name\n",
    "    @Param datetime day0: reference date\n",
    "    @Param str fmt: date time format\n",
    "    '''\n",
    "    dat[col] = pd.to_datetime(dat[col], format=fmt, errors='ignore')\n",
    "    for index in dat[col].index:\n",
    "        dat.loc[index, col] = day0 - dat.loc[index, col]\n",
    "        dat.loc[index, col] = dat.loc[index, col].total_seconds() / (24 * 60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B6: Latest transfer time\n",
    "X['B6'] = pd.to_datetime(X['B6'], format=fmt, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jinink/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Users/Jinink/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961 ms ± 12.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# B6: Latest transfer time\n",
    "day0 = datetime(2019, 12, 31)\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "%timeit code_df_dummy(X.loc[0:1000, :], 'B6', day0, fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E category\n",
    "day0 = datetime(2019, 12, 31)\n",
    "fmt = '%Y-%m-%d'\n",
    "col_names = ['E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E10', 'E16', 'E18']\n",
    "for col_name in col_names:\n",
    "    code_df_dummy(X, col_name, day0, fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I1: Gender\n",
    "code_cat_dummy(X, 'I1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I3: Class\n",
    "code_cat_dummy(X, 'I3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I5: Occupation\n",
    "code_cat_dummy(X, 'I5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X_true (Features for Testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "Similar to the `X`, we first processed missing values in the data. Multiple columns contain missing values. The percentage of missing values in each column ranges from 0.0048% to 100.00%. We removed columns containing large portion of missing values.\n",
    "\n",
    "### Drop Meaningless Columns\n",
    "\n",
    "Based on the codebook, after mining into the data, we determined that the following columns contain meaningless information and, therefore, we dropped these columns:\n",
    "\n",
    "- `I8`: constellation. We don't believe constellation can alter customer behavior.\n",
    "- `I12`: field description. Contain only 1 different values.\n",
    "- `I15`: QR code recipient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "check_missing(X_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_true_original = X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with large portion of missing values\n",
    "col_to_drop = ['E7', 'E8', 'E9', 'E11', 'E12', 'E13', 'I9', 'I10', 'I13', 'I14',\n",
    "              'I8', 'I12', 'I15']\n",
    "X_true = X_true.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('After dropping columns containing large portion of missing values and meaningless columns, now the set has {} columns.'.format(X_true.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Coding\n",
    "\n",
    "Before applying `Datawig`, we dummy coded categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B6: Latest transfer time\n",
    "day0 = datetime(2019, 12, 31)\n",
    "fmt = '%Y-%m-%d %H:%M:%S'\n",
    "code_df_dummy(X, 'B6', day0, fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E category\n",
    "day0 = datetime(2019, 12, 31)\n",
    "fmt = '%Y-%m-%d'\n",
    "col_names = ['E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E10', 'E16', 'E18']\n",
    "for col_name in col_names:\n",
    "    code_df_dummy(X, col_name, day0, fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I1: Gender\n",
    "code_cat_dummy(X, 'I1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I3: Class\n",
    "code_cat_dummy(X, 'I3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I5: Occupation\n",
    "code_cat_dummy(X, 'I5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
