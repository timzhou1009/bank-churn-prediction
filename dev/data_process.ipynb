{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commercial Bank Customer Retention Prediction\n",
    "\n",
    "## APSTA-GE.2401: Statistical Consulting\n",
    "\n",
    "## Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created on: 12/08/2020\n",
    "\n",
    "Modified on: 12/08/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This script processes data from the proprocess step.\n",
    "\n",
    "### Data\n",
    "\n",
    "The data are preprocessed feature sets:\n",
    "\n",
    "  - `X_train.csv`: contains all features in Q3 and Q4 of 2019 for training. Imported as `X`.\n",
    "  - `y_train.csv`: contains the label variable for validation. Imported as `y`.\n",
    "  - `X_test.csv`: contains all features in Q1 of 2020 for testing. Imported as `X_true`.\n",
    "   \n",
    "After importing the data, we confirmed that both train sets have the same number of records: **145296**. We also confirmed that the testing set has **76722** records.\n",
    "\n",
    "### Procedures\n",
    "\n",
    "We first inspected the feature set. \n",
    "\n",
    "1. There are 55 features in the feature set. \n",
    "\n",
    "2. We checked if there are any missing values in the set. We found multiple columns that contain missing values, ranging from 0.005% to 100%. For columns containing a large portion of missing values, we dropped the column to reduce computational burden. For columns containing a small portion of missing values, we applied a deep learning library, [Datawig](https://github.com/awslabs/datawig), which learns machine learning models using deep neural networks to impute missing values in the data.\n",
    "\n",
    "    - After dropping columns containing large portion of missing values, we reduced number of features to 45.\n",
    "\n",
    "3. We then performed dummy coding to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS! All modules are imported.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('SUCCESS! All modules are imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/preprocess/X_train.csv')\n",
    "y = pd.read_csv('../data/preprocess/y_train.csv')\n",
    "X_true = pd.read_csv('../data/preprocess/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proprocessed training set has 145296 rows and 56 columns.\n",
      "The proprocessed validation set has 145296 rows and 2 columns.\n",
      "The proprocessed testing set has 76722 rows and 56 columns.\n"
     ]
    }
   ],
   "source": [
    "print('The proprocessed training set has {} rows and {} columns.'.format(X.shape[0], X.shape[1]))\n",
    "print('The proprocessed validation set has {} rows and {} columns.'.format(y.shape[0], y.shape[1]))\n",
    "print('The proprocessed testing set has {} rows and {} columns.'.format(X_true.shape[0], X_true.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "We first processed missing values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B6 has 8878 missing values. (6.1103%)\n",
      "E2 has 6370 missing values. (4.3842%)\n",
      "E3 has 6370 missing values. (4.3842%)\n",
      "E4 has 84483 missing values. (58.1454%)\n",
      "E5 has 55129 missing values. (37.9425%)\n",
      "E6 has 7538 missing values. (5.1880%)\n",
      "E7 has 142402 missing values. (98.0082%)\n",
      "E8 has 127381 missing values. (87.6700%)\n",
      "E9 has 145227 missing values. (99.9525%)\n",
      "E10 has 816 missing values. (0.5616%)\n",
      "E11 has 145296 missing values. (100.0000%)\n",
      "E12 has 121324 missing values. (83.5013%)\n",
      "E13 has 127502 missing values. (87.7533%)\n",
      "E14 has 90010 missing values. (61.9494%)\n",
      "E16 has 68530 missing values. (47.1658%)\n",
      "E18 has 62147 missing values. (42.7727%)\n",
      "C1 has 7 missing values. (0.0048%)\n",
      "C2 has 7 missing values. (0.0048%)\n",
      "I1 has 64 missing values. (0.0440%)\n",
      "I5 has 11604 missing values. (7.9865%)\n",
      "I9 has 145296 missing values. (100.0000%)\n",
      "I10 has 128487 missing values. (88.4312%)\n",
      "I13 has 143108 missing values. (98.4941%)\n",
      "I14 has 129650 missing values. (89.2316%)\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing_val = X.isnull().sum()\n",
    "for index in missing_val.index:\n",
    "    if missing_val[index] > 0:\n",
    "        print('{} has {} missing values. ({:.4%})'.format(index, missing_val[index], missing_val[index]/len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
